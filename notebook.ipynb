{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Standard Naive Bayes on the Medline Dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chosen Representation Of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to identify the k most frequently occuring words from all of the abstracts,where each word from the k  most frequently occuring words, will be used as an attribute for the X data. \n",
    "\n",
    "(note that my final improved classifier uses k = 200)\n",
    "\n",
    "Each value in each attribute is the frequency of that word for that instance's abstract. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / Test Split before Preprocessing: \n",
    "- Before I preprocess the data into the chosen data representation, I first split the entire dataset into a training and testing set. This is because, if I were instead  to preprocess all of the data, and then split it into train and test sets, I would be violating a fundamental rule of Machine learning - that the test data should not \"see\" any part of the training data.\n",
    "\n",
    "\n",
    "- This is because, the result of my preprocessing on the test set would otherwise be influenced by the result of my preprocessing in the training set. I avoid this, by first splitting the data into train and test sets. \n",
    "\n",
    "Data Preprocessing: \n",
    "- My Naive Bayes Classifier takes a feature numpy array and a class numpy array as input during its training phase. These arrays do not store the ID of each instance. This works, because the order of IDS are maintaned, and the training data is not actually used when making predictions. \n",
    "\n",
    "\n",
    "- Because the Naive Bayes Classifier takes numpy arrays as Input,  as part of my preprocessing step, I convert the data into Numpy Arrays. \n",
    "\n",
    "\n",
    "- However, the feature data contains one long piece of text as the instance's abstract. I dont want just one attribute to be used to train the model, as almost all instances contain a different abstract. Instead, I want to train the model on a number of different words, by taking the frequency of the words into account. I am using a Multinomial Naive Bayes Model, where the number of times that a woprd appears in an instance's abstract is the value for the instance at that word. \n",
    "\n",
    "\n",
    "- Because of this, In my preprocessing phase, I first grab the most common k words from all of the X data's instance's abstracts, where k = 10 for the standard Naive Bayes Model. Using these most common k words, for each instance in the X data, I remove its abstract value and replace it with k new attributes, where each attribute represents a word in the most common k words. Because I chose to use a Multinomial Naive Bayes Model, the value for each attribute is equal to the number of times that the word at the attribute represents, appears in the instance's abstract. I am taking the frequency of each word into account. \n",
    "\n",
    "\n",
    "- My final step of Preprocessing is to turn the new X data into a numpy array, where row i, is equal to a numpy array, consisting of the attribute values of instance i. (The ID of the instance is not used in the model). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions used for Preprocessing and Model Evaulation, as well as finding an improved model to the standard Naive Bayes model: \n",
    "- def load_data(filename):\n",
    "This is used to load all of the data with the given filename, and return a feature array, a class array and all of the abstracts as a list. \n",
    "The feature array is returned in the form, [[ID, abstract], ...] and the class array is returned in the form, [[ID, class], ...]. \n",
    "\n",
    "\n",
    "- def get_train_test_split(feature_data, class_data):\n",
    "This splits the entire dataset into training and testing sets. 80% of the data is used for training. I first grab a permutaion, and then split the feature_data and class_data accordingly to return training X and Y sets, as well as testing X and Y sets. \n",
    "\n",
    "\n",
    "- def get_most_common_K_words(all_abstracts, k):\n",
    "I use the Counter class to quickly find the most common k words from all of the abstracts inputted, and I return an ordered list containg these most common k words, in order of most common to least common.\n",
    "\n",
    "\n",
    "- def number_of_times_word_in_abstract(abstract, word):\n",
    "Returns the count of how many times the word appears in an instance's abstract. This is important because I am using multinomial Naive bayes and need the frequencies of each word for an instance. \n",
    "\n",
    "\n",
    "- def preprocess(X_array, words):\n",
    "Here I convert the X_array from [ID, [long piece of text]] to [ID, [word1_frequency, word2_frequency, ... wordk_frequency]]. \n",
    "\n",
    "\n",
    "\n",
    "- def values_only_no_IDS(X_data, Y_data):\n",
    "Here I only grab values for each instance, and not their IDS, I then return a numpy array for the values from the feature array as well as the values from the class array. \n",
    "\n",
    "\n",
    "- def get_percentage_correct(predictions, actual_values):\n",
    "I return the percentage of classes correctly classified from the predictions array using an array of the actual values. \n",
    "This is my main scoring metric for the classifiers, simply how accurate it is. \n",
    "\n",
    "\n",
    "- def get_k_splits(feature_data, class_data, k):\n",
    "Here, I split the data into k different splits. This is used in the next function for performing cross validation. \n",
    "\n",
    "\n",
    "- def run_cross_validation(nb, feature_data, class_data, words, k):\n",
    "I run k fold cross vaidation on the classifier, generating a new accuracy for each fold. I use k = 10, for all cross validation performed in this assingment. \n",
    "\n",
    "\n",
    "- def find_best_number_words(X_train, X_test, Y_train, Y_test, all_abstracts):\n",
    "I use this to train a few different classifiers, where each classifier uses a different number of most common words as the attributes for each instance. \n",
    "\n",
    "- def normalise_word_frequencies(feature_array, words):\n",
    "I use this in an attempt to improve the models accuracy, by normalising the word frequencies for each instance. \n",
    "\n",
    "\n",
    "- def run_cross_validation_normalisation(nb, feature_data, class_data, words, k):\n",
    "This is the same as my previous cross validation function, execpt that it performs cross validation on data that has its word frequencies normalsied as per the above function.\n",
    "\n",
    "\n",
    "- def load_test_data(filename):\n",
    "I use this to load the test data set, as the test data only contains the IDS and their abstracts, so I need to load this data differently as the training data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Naive Bayes Implementaion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first expirmented by implmenting the Naive bayers classifier via many different functions. I would first grab the data and generate a dictionary containing the prior values. Then I would generate a dictionary containing the conditional probability values and so forth. \n",
    "\n",
    "However, the run time for this was much too high, especially when trying to debug, and improve the code. \n",
    "\n",
    "My final Naive Bayes implementaion ended up being a class, NaiveBayesClassifier. I found that the run time of my code drastically improved, however improvements are still possible. \n",
    "\n",
    "How the Implementation Works: \n",
    "- The class has a few methods, train(self, X_data, Y_data), get_posterior(self, w, c, X_data, Y_data),  make_predictions_on_X_data(self, new_X_data), make_prediction_on_instance(self, instance, new_X_data) and two get methods, get_conditional_probs(self) and get_priors(self). \n",
    "\n",
    "\n",
    "- Creating: When I instantiate a Naive Bayes Classifier, I instantiate it as per normal, nb = NaiveBayesClassifier(). \n",
    "\n",
    "\n",
    "- Training: When I train the classifier, I pass in the processed feature numpy array as well as the processed class array into the train() method. In this training phase, I set up a list of the prior proabilities for each unique class in the class numpy array. I also set up a dictionary that contains the conditional probabilities of each word and unqiue class combination. \n",
    "\n",
    "\n",
    "- Getting priors: For each unioque class, I divide the number of times an instance has this class by the total number of instances. \n",
    "\n",
    "\n",
    "- Getting conditional probabilities: for each attribute/word and unique class coombination, I find the combination's posterior probability by calling the get_posterior()'s method. This performs the P(w|c) calculation from the lecture slides. \n",
    "\n",
    "\n",
    "\n",
    "- Making Predictions: When I want to make predictions on some X_data I call the make_predictions_on_X_data() method which loops through each instance in the X_data and returns the ouput of the make_prediction_on_instance() method, see below. \n",
    "\n",
    "\n",
    "- The make_prediction_on_instance() method: For a given instance this returns the most likley class, by finding the probability that it is each individual unique class and returning the most likley class. For each attribute in the instance, it  the proabbility that the true class  is the one being tested. this is done by, prior probability + the sum of all of the conditional probabilities for each attribute in the instance. \n",
    "\n",
    "\n",
    "- The get methods in this class are self explanatory. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Naive Bayes Performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When ever I try to find the performance of a model, I run 10 fold cross validation on that model, and find the percentage of classes correctly classified for each fold, I then return the average percentage. (for the training and testing data.)\n",
    "\n",
    "When running 10 fold cross validation on a model I pass in the non processed data, because when I feed data to the Naive Bayes Classifier, it assumes that the data is already in the correct order, this is why I first process each fold's data accordingly keeping track of the relevant order for each fold, and then make a prediction on that fold.  \n",
    "\n",
    "\n",
    "I run 10 fold cross validation, in order to get more of an undertstanding as to how well I can expect the model to perform with future unforseen data, the test data csv. \n",
    "\n",
    "\n",
    "Performance of Standard Naive Bayes Model: \n",
    "- After running repeated 10 fold cross validation on the standard Naive Bayes Model, that has been trained on using 10 words I get an average of 59% accuracy on the training set and 60%  accuracy on the test data.\n",
    "\n",
    "\n",
    "- Note that due to Random shufflings, the reader of this document can expect to find slightly different values. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Naive Bayes Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few methods that I use as an attempt to improve the accuracy of the model. \n",
    "\n",
    "\n",
    "Optimal Number of Words to Train on: \n",
    "- I first find the optimal number of words to use on the classifier, which turns out to be 200. I would have guessed that there was a proportional relationship between number of words for the classifier and the classifiers accuracy. This was true untill a threshold of 200 words, where the performance of the models begins to decrease from there on out. \n",
    "\n",
    "\n",
    "- I expect this to be due to the intuition that after the threshold, the explanatory power of the additional attributes fades, as they could be essentially adding noise to the model, as these additional attributes take away from the predictive ability of the other attributes that are able to predict reasonably well.\n",
    "\n",
    "- I then found the 10 fold cross validation scores on the training and testing data for a few different models, where each model used a different number of words for the attributes of each instance. \n",
    "\n",
    "- The model that had the greatest CV score, was the model trained on 200 words, So, I decieded to train the future models using 200 words, as this seemed to give the best accuracy for the testing data. \n",
    "\n",
    "\n",
    "Normalising Word Frequencies: \n",
    "\n",
    "- I noticed that some instances had a relatively large ferquency for some attribute values as compared to the other instances. I hypothesises that this was the result of the fact that once a word appears in an instance's abstract, it is much more likley to reappear in that instance's abstract again. Leading to instances with long abstracts recieving a larger weighting,  for conditional probabilities on the model.  \n",
    "\n",
    "\n",
    "- Normalising word frequencies was added as an additional preprocessing step. Where s = sum of all word frequencies for the abstract,  I made the new word frequency for each word at a given abstract = its old word frequency / srt(s^2). \n",
    "\n",
    "\n",
    "- I then trained a new Naive Bayes Classifier on 200 attributes, where the values at each attribute had now been processed as per above. \n",
    "\n",
    "\n",
    "- Using the 10 fold cross validation of this new model on the training data and testing data, and found that Normalising the word frequencies actually decreased the model's performance. I will not be using this in the final model. \n",
    "\n",
    "\n",
    "Finding  probabilities via Loagrithims: \n",
    "\n",
    "- I decided to try and improve the models performance by finding the probability that the real class is some given class via logarithims. \n",
    "\n",
    "\n",
    "- This is because the model was storing very small probabilities in its conditional probabilities dictionary. I thought that it could be possible that there is a loss of information and therefore inaccurate probability when trying to make the predictions on an instance. this is because, I would be multiplying many very small probabilities together. So I decedied to instead try, summing logarithims of probabilities instead. \n",
    "\n",
    "\n",
    "- I made a new naivebayesLogarithim Class that behaves exactly the same way as the previous class, except for a few minor changes in the make_prediction_on_instance(self, instance, new_X_data) method of the class. Instead of multiplying together the probabilities, I summed the logarithims of the probabilities. \n",
    "\n",
    "\n",
    "- Using the CV scores for the training and testing data, it turned out that this did not increase the performance of the model. \n",
    "\n",
    "\n",
    "- So I will not be using this change in the final Naive Bayes Classifier. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Naive Bayes Model  Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance can be found under the heading, Final Naive Bayes Classifier, near the bottom of the notebook. \n",
    "\n",
    "The final Naive Bayes Classifier was trained on 200 words, using the logarithim of the probabilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from random import randrange\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    #load the data into a feature array, class array and list with all of the abstracts. \n",
    "    feature_array = []\n",
    "    class_array = []\n",
    "    all_abstracts = []\n",
    "    data = np.loadtxt(filename, dtype = str, delimiter = \",\")\n",
    "    for row in data[1:]: \n",
    "        feature_array.append((int(row[0]), row[2].split()))\n",
    "        class_array.append((int(row[0]), row[1]))\n",
    "        for x in row[2].split():\n",
    "            all_abstracts.append(x)        \n",
    "    return np.array(feature_array), np.array(class_array), np.array(all_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UNI\\AppData\\Local\\Temp/ipykernel_9404/3198737044.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(feature_array), np.array(class_array), np.array(all_abstracts)\n"
     ]
    }
   ],
   "source": [
    "filename = \"data/trg.csv\" \n",
    "feature_array, class_array, all_abstracts = load_data(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into Train/Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I split the data into train and test sets before preprocessing, because in preprocessing, I replace the single attribute with N attributes, \n",
    "(a1, a2, ..., an) where each a_i is a word that occurs the ith most often in the total text of the data and N = number of most common words I am using as attributes. \n",
    "\n",
    "If I instead were to preprocess all of the data, and then split it into train and test sets, I would be violating a rule of Machine elarning, that the test set should not \"see\" any part of the train set. \n",
    "This is because the frequencey of the word for both the train and test sets (all of the data) would be taken into account for the the frequencey of the words and thus attributes for each instance, in the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(feature_data, class_data):\n",
    "    #Splits the feature data and the class data into relevenat train and test splits. \n",
    "    N = len(feature_data)\n",
    "    train_set_size = math.floor(0.8 * N)\n",
    "    \n",
    "    random_number_generator = np.random.default_rng()\n",
    "    permutation = random_number_generator.permutation(N)\n",
    "    train = permutation[:train_set_size]\n",
    "    test = permutation [train_set_size:]\n",
    "    \n",
    "    X_train = feature_data[train]\n",
    "    X_test = feature_data[test]\n",
    "    Y_train = class_data[train]\n",
    "    Y_test = class_data[test]\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test =  get_train_test_split(feature_array, class_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreProcessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want the data to have attributes other than just a long peice of text. \n",
    "I will choose to make the attributes to be the N most frequently occuring words of all of the words in all of the abstracts for an instance. \n",
    "\n",
    "I am implementing multinomial Naive Bayes, such that the value for each instance at each attribute = the number of times that the attribute word appears in the instance's abstract.  \n",
    "\n",
    "Such that the data will look like this: \n",
    "\n",
    "ID, Word1, Word2, ..., WordN\n",
    "\n",
    "1, 1, 0, 3\n",
    "\n",
    "This first row, means that the instance with ID of 1, is of class B and in its attributes, it contains Word1 once, does not contain Word2 etc...\n",
    "\n",
    "Note that I only preprocess the X_train and X_test sets, as these are the only sets that actually contain the attribute values I want. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_K_words(all_abstracts, k):\n",
    "    #returns the k most common words from all of the the abstracts in the X training data. \n",
    "    counter = Counter(all_abstracts)\n",
    "    return [x[0] for x in counter.most_common(k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_words = get_most_common_K_words(all_abstracts, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_times_word_in_abstract(abstract, word):\n",
    "    #Returns the number of times that a word is in a given abstract. \n",
    "    count = 0\n",
    "    for w in abstract: \n",
    "        if w == word: \n",
    "            count +=1 \n",
    "    return count\n",
    "    \n",
    "def preprocess(X_array, words):\n",
    "    #Preprocess the X data by changing its attributes to [....] = new, |new| = number of words. \n",
    "    N = len(words)\n",
    "    processed_array = []\n",
    "    for instance in X_array:\n",
    "        ID = int(instance[0])\n",
    "        attributes = [number_of_times_word_in_abstract(instance[1], words[i]) for i in range(N)]       \n",
    "        processed_array.append([instance[0], attributes])\n",
    "    return np.array(processed_array)\n",
    "\n",
    "def values_only_no_IDS(X_data, Y_data):\n",
    "    #Return only the values of the arrays. (NaiveBayesClassifier does not use the IDS)\n",
    "    new_X = [x[1] for x in X_data]\n",
    "    new_Y = [y[1] for y in Y_data]    \n",
    "    return np.array(new_X), np.array(new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UNI\\AppData\\Local\\Temp/ipykernel_9404/1251427178.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(processed_array)\n"
     ]
    }
   ],
   "source": [
    "preprocessed_X_train = preprocess(X_train, most_common_words)\n",
    "preprocessed_X_test = preprocess(X_test, most_common_words)\n",
    "final_X_train, final_Y_train = values_only_no_IDS(preprocessed_X_train, Y_train)\n",
    "final_X_test, final_Y_test = values_only_no_IDS(preprocessed_X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Standard Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    \n",
    "    def train(self, X_data, Y_data): #Takes X_data as an array of arrays containing only the values from the feature_data. \n",
    "        X_data = np.array(X_data)\n",
    "        Y_data = np.array(Y_data)\n",
    "        \n",
    "        self._num_instances, self._num_features = X_data.shape        \n",
    "        self._unique_classes = np.unique(Y_data)\n",
    "        self._num_unique_classes = len(self._unique_classes)\n",
    "        self._prior_probs = np.zeros(self._num_unique_classes) #Initialise the prior probabilities. \n",
    "\n",
    "        #Get Prior probabilities:\n",
    "        for i, c in enumerate(self._unique_classes):\n",
    "            instances_with_class_c = X_data[Y_data == c] #All the instances from X data that have the class c. \n",
    "            self._prior_probs[i] = instances_with_class_c.shape[0] / self._num_instances\n",
    "\n",
    "        #Get Posterior probabilties: \n",
    "        self._conditional_probs = {}\n",
    "        for x in range(self._num_features):\n",
    "            self._conditional_probs[x] = {c:self.get_posterior(x, c, X_data, Y_data) for c in self._unique_classes}\n",
    "\n",
    "\n",
    "    def get_posterior(self, w, c, X_data, Y_data):\n",
    "        #Returns the posterior probability, P(w|c):\n",
    "        posterior = 0\n",
    "        numerators = 0\n",
    "        denominators = 0\n",
    "        \n",
    "        instances_with_class_c = X_data[Y_data == c]#All the instances from X data that have the class c. \n",
    "        \n",
    "        for instance in instances_with_class_c:\n",
    "            numerators = numerators + instance[w]\n",
    "            denominators = denominators + sum(instance)\n",
    "        return (numerators + 1) / (denominators + self._num_features) #Adding 1 to numerator and |V| to denominator to avoid multiplying by zeroes. \n",
    "            \n",
    "    def make_predictions_on_X_data(self, new_X_data):\n",
    "        #Returns list of predictions for each instance in X data. \n",
    "        predictions = [self.make_prediction_on_instance(instance, new_X_data) for instance in new_X_data]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def make_prediction_on_instance(self, instance, new_X_data):       \n",
    "        #Returns the prediction of a single instance in X data. \n",
    "        \n",
    "        max_prob = 0 #Initialising greatest probability. \n",
    "        max_class = \"A\" #Initialising most likely class. \n",
    "\n",
    "        for i in range(len(self._unique_classes)): #For each class: \n",
    "            prob = self._prior_probs[i] #Initialise the probability for the class to its prior value. \n",
    "            for w in self._conditional_probs.keys():\n",
    "                if instance[w] != 0: #Make sure instance[word] has a frequency. \n",
    "                    prob = prob * (self._conditional_probs[w][self._unique_classes[i]] ** instance[w]) #Grab the probability. \n",
    "                    \n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                max_class = self._unique_classes[i]\n",
    "                \n",
    "                \n",
    "        #Evaluate the class with the highest probability. \n",
    "        \n",
    "        return max_class\n",
    "       \n",
    "    def get_conditional_probs(self):\n",
    "        return self._conditional_probs\n",
    "    \n",
    "    def get_priors(self):\n",
    "        return  self._prior_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_nb = NaiveBayesClassifier()\n",
    "standard_nb.train(np.array(final_X_train), np.array(final_Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percentage_correct(predictions, actual_values):\n",
    "    #Returns the percentage of correctly classified instances. \n",
    "    N = len(predictions)\n",
    "    correct = 0\n",
    "    for i in range(N):\n",
    "        if predictions[i] == actual_values[i]:\n",
    "            correct += 1\n",
    "        \n",
    "    return (correct / N) * 100\n",
    "\n",
    "def get_k_splits(feature_data, class_data, k):# Split data into k splits. \n",
    "    splits_X = []   \n",
    "    number_of_folds = k\n",
    "    splits_Y = []\n",
    "    \n",
    "    for i in range(number_of_folds): # Creating the k folds. \n",
    "        feature_data_copy = list(feature_data)\n",
    "        class_data_copy = list(class_data)\n",
    "        size_of_fold = len(feature_data_copy) / number_of_folds\n",
    "\n",
    "        fold = []\n",
    "        fold_Y = []\n",
    "        while (len(fold)) < (size_of_fold): \n",
    "            index = random.randrange(len(feature_data_copy) ) #Random index in feature_data_copy. \n",
    "            fold.append(feature_data_copy[index])\n",
    "            fold_Y.append(class_data_copy[index])\n",
    "            feature_data_copy.pop(index) #Cant choose the same item more than once\n",
    "            class_data_copy.pop(index)\n",
    "            \n",
    "        splits_X.append(fold)\n",
    "        splits_Y.append(fold_Y)\n",
    "    return splits_X, splits_Y\n",
    "\n",
    "def run_cross_validation(nb, feature_data, class_data, words, k):\n",
    "    #Runs cross validation on k splits. \n",
    "    list_of_percentage_corrects_for_each_fold = [] \n",
    "    \n",
    "    splits_X, splits_Y = get_k_splits(feature_data,class_data, k) #Get k splits.\n",
    "    \n",
    "    for i in range(len(splits_X)):\n",
    "        split_X = splits_X[i]\n",
    "        split_Y = splits_Y[i]\n",
    "        processed_split_X = preprocess(split_X, words)      \n",
    "        \n",
    "        final_X_split, final_Y_split = values_only_no_IDS(processed_split_X, split_Y)  \n",
    "\n",
    "        predictions_on_split = nb.make_predictions_on_X_data(final_X_split)\n",
    "\n",
    "        percentage_correct = get_percentage_correct(predictions_on_split, final_Y_split)\n",
    "        \n",
    "        list_of_percentage_corrects_for_each_fold.append(percentage_correct)\n",
    "  \n",
    "    N = len(list_of_percentage_corrects_for_each_fold)\n",
    "    return sum(list_of_percentage_corrects_for_each_fold) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-fae0cdd28a82>:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(processed_array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Training Data: \n",
      "Average percentage of classes corrrectly classified on 10 splits =  60.34375\n",
      "On Testing/Validation Data\n",
      "Average percentage of classes corrrectly classified on 10 splits =  65.25\n"
     ]
    }
   ],
   "source": [
    "num_splits = 10\n",
    "train_CV_score = run_cross_validation(standard_nb, X_train, Y_train, most_common_words, num_splits)\n",
    "\n",
    "print(\"On Training Data: \")\n",
    "print(\"Average percentage of classes corrrectly classified on\", num_splits, \"splits = \", train_CV_score)\n",
    "\n",
    "test_CV_score = run_cross_validation(standard_nb, X_test, Y_test, most_common_words, num_splits)\n",
    "print(\"On Testing/Validation Data\")\n",
    "print(\"Average percentage of classes corrrectly classified on\", num_splits, \"splits = \", test_CV_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fining The Best Number of Words to Train On"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to improve the accuracy of the standard Naivebayes Classifier. Many of the methods that I hope will increase the accuracy of the Naive bayes Classifier,  lie in the preprocessing part of the data. \n",
    "\n",
    "I first want to see how increasing the words/number of attributes that an instance has, influences the accuracy of the model. \n",
    "\n",
    "I will grab the most accuracte model for a few different numbers of words. \n",
    "\n",
    "**Note that the below code take a reasonable while to run, to save the marker some time, the model performs the best on 200 words. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_number_words(X_train, X_test, Y_train, Y_test, all_abstracts):\n",
    "    best_CV_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    numbers = [50, 100, 150, 200, 300]\n",
    "    for number in numbers:\n",
    "        most_common_words = get_most_common_K_words(all_abstracts, number)\n",
    "        \n",
    "        preprocessed_X_train = preprocess(X_train, most_common_words)\n",
    "        preprocessed_X_test = preprocess(X_test, most_common_words)\n",
    "        final_X_train, final_Y_train = values_only_no_IDS(preprocessed_X_train, Y_train)\n",
    "        final_X_test, final_Y_test = values_only_no_IDS(preprocessed_X_test, Y_test)\n",
    "\n",
    "        nb = NaiveBayesClassifier()\n",
    "        nb.train(np.array(final_X_train), np.array(final_Y_train))\n",
    "\n",
    "        num_splits = 10\n",
    "        CV_score = run_cross_validation(nb, X_train, Y_train, most_common_words, num_splits)\n",
    "\n",
    "\n",
    "        if CV_score > best_CV_score:\n",
    "            best_CV_score = CV_score\n",
    "            best_model = nb\n",
    "            \n",
    "        test_CV_score = run_cross_validation(nb, X_test, Y_test, most_common_words, num_splits)\n",
    "\n",
    "        print(\"--------------------\")\n",
    "        print(\"Number of words =\", number)\n",
    "        print(\"Training Data CV Score: \")\n",
    "        print(\"Average percentage of classes corrrectly classified on\", num_splits, \"splits = \", CV_score)\n",
    "        \n",
    "        print(\"testing Data CV Score: \")\n",
    "        print(\"Average percentage of classes corrrectly classified on\", num_splits, \"splits = \", test_CV_score)\n",
    "        \n",
    "        print(\"--------------------\")\n",
    "    \n",
    "    return best_model, number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-fae0cdd28a82>:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(processed_array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Number of words = 50\n",
      "Training Data CV Score: \n",
      "Average percentage of classes corrrectly classified on 10 splits =  70.71875\n",
      "testing Data CV Score: \n",
      "Average percentage of classes corrrectly classified on 10 splits =  72.125\n",
      "--------------------\n",
      "--------------------\n",
      "Number of words = 100\n",
      "Training Data CV Score: \n",
      "Average percentage of classes corrrectly classified on 10 splits =  77.03125\n",
      "testing Data CV Score: \n",
      "Average percentage of classes corrrectly classified on 10 splits =  77.0\n",
      "--------------------\n",
      "--------------------\n",
      "Number of words = 150\n",
      "Training Data CV Score: \n",
      "Average percentage of classes corrrectly classified on 10 splits =  79.9375\n",
      "testing Data CV Score: \n",
      "Average percentage of classes corrrectly classified on 10 splits =  75.75\n",
      "--------------------\n",
      "--------------------\n",
      "Number of words = 200\n",
      "Training Data CV Score: \n",
      "Average percentage of classes corrrectly classified on 10 splits =  83.09375\n",
      "testing Data CV Score: \n",
      "Average percentage of classes corrrectly classified on 10 splits =  79.625\n",
      "--------------------\n",
      "--------------------\n",
      "Number of words = 300\n",
      "Training Data CV Score: \n",
      "Average percentage of classes corrrectly classified on 10 splits =  79.28125\n",
      "testing Data CV Score: \n",
      "Average percentage of classes corrrectly classified on 10 splits =  73.25\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "###Note that this Code fragment takes a reasonably long time to load. \n",
    "\n",
    "best_nb, number_words = find_best_number_words(X_train, X_test, Y_train, Y_test, all_abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to see that the best model was trained on instances having  200 words/attributes. \n",
    "\n",
    "I will now continue to try and improve this model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalising Word Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to see what the effect of normalising the word frequency values has. This is because, when a word is first used in an abstract / piece of text it is much more likley to be reuseed again in the same abstract/text. This leads to instances with larger abstracts dominating the probbailities of the Naivebayes Classifier. \n",
    "\n",
    "I will normalise via: \n",
    "-  s = sum of all word frequencies for the abstract. \n",
    "- newWordFrequency = oldWordfrequency / sqrt(s^2)\n",
    "\n",
    "\n",
    "*Note that I need to change my Cross Validation code, as the preprocessing for the data is now different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_word_frequencies(feature_array, words):\n",
    "    new_X_set = [[x[0], x[1]] for x in feature_array]\n",
    "    for i in range(len(feature_array)):\n",
    "        feature = feature_array[i]\n",
    "        word_frequencies = feature[1]\n",
    "        sum_of_frequencies = sum(word_frequencies)\n",
    " \n",
    "        for n in range(len(word_frequencies)):\n",
    "            value = word_frequencies[n]       \n",
    "            if value != 0:\n",
    "                new_value = value / math.sqrt(sum_of_frequencies ** 2)                \n",
    "                new_X_set[i][1][n] = new_value\n",
    "            else:\n",
    "                new_X_set[i][1][n] = new_value = value\n",
    "    return new_X_set  \n",
    "\n",
    "\n",
    "def run_cross_validation_normalisation(nb, feature_data, class_data, words, k):\n",
    "    #Runs cross validation on k splits. \n",
    "    list_of_percentage_corrects_for_each_fold = [] \n",
    "    \n",
    "    splits_X, splits_Y = get_k_splits(feature_data, class_data, k) #Get k splits.\n",
    "    \n",
    "    for i in range(len(splits_X)):\n",
    "        split_X = splits_X[i]\n",
    "        split_Y = splits_Y[i]        \n",
    "        processed_split_X = preprocess(split_X, words) \n",
    "        normalsied_frequenciess_X_split = normalise_word_frequencies(processed_split_X, words) #Normalise the frequencies of each fold.         \n",
    "        final_X_split, final_Y_split = values_only_no_IDS(normalsied_frequenciess_X_split, split_Y)  \n",
    "\n",
    "        predictions_on_split = nb.make_predictions_on_X_data(final_X_split)\n",
    "        percentage_correct = get_percentage_correct(predictions_on_split, final_Y_split)\n",
    "        \n",
    "        list_of_percentage_corrects_for_each_fold.append(percentage_correct)\n",
    "  \n",
    "    N = len(list_of_percentage_corrects_for_each_fold)\n",
    "    return sum(list_of_percentage_corrects_for_each_fold) / N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-fae0cdd28a82>:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(processed_array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data CV score:\n",
      "Average percentage of classes corrrectly classified on 10 splits =  53.875\n",
      "Testing Data CV score:\n",
      "Average percentage of classes corrrectly classified on 10 splits =  54.375\n"
     ]
    }
   ],
   "source": [
    "#Training the model with normalised word frequencies and 200 words. \n",
    "\n",
    "#setting up X data and Y data:\n",
    "most_common_words = get_most_common_K_words(all_abstracts, 200)\n",
    "\n",
    "new_preprocessed_X_train = preprocess(X_train, most_common_words)\n",
    "new_preprocessed_X_test = preprocess(X_test, most_common_words)\n",
    "\n",
    "normalised_X_train = normalise_word_frequencies(new_preprocessed_X_train, most_common_words)\n",
    "normalsied_X_test = normalise_word_frequencies(new_preprocessed_X_test, most_common_words)\n",
    "\n",
    "new_final_X_train, new_final_Y_train = values_only_no_IDS(normalised_X_train, Y_train)\n",
    "new_final_X_test, new_final_Y_test = values_only_no_IDS(normalsied_X_test, Y_test)\n",
    "\n",
    "normalised_200_NaiveBayes = NaiveBayesClassifier()\n",
    "normalised_200_NaiveBayes.train(np.array(new_final_X_train), np.array(new_final_Y_train))\n",
    "\n",
    "num_splits = 10\n",
    "CV_score = run_cross_validation_normalisation(normalised_200_NaiveBayes, X_train, Y_train, most_common_words, num_splits)\n",
    "print(\"Training Data CV score:\")\n",
    "print(\"Average percentage of classes corrrectly classified on\", num_splits, \"splits = \", CV_score) \n",
    "\n",
    "Test_CV_score = run_cross_validation_normalisation(normalised_200_NaiveBayes, X_test, Y_test, most_common_words, num_splits)\n",
    "print(\"Testing Data CV score:\")\n",
    "print(\"Average percentage of classes corrrectly classified on\", num_splits, \"splits = \", Test_CV_score) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalising the frequcnies negatively impacted the models performance. I will not be using this for the final Naive Bayes Classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Probabilities with Logarithims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probabbilities that my model generates are extermely small, so when I multiply these small probabilities together, this leads to even smaller probabilities. \n",
    "\n",
    "It is possible that these very small probabilities are not beinig precisely stored in the model. \n",
    "\n",
    "I will therefore change the NaiveBayes model so that it finds the probabilities by adding together loagrithims instead. \n",
    "\n",
    "(I will again be using 200 words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The change is made under method, make_prediction_on_instance()\n",
    "\n",
    "class NaiveBayesClassifierLogarithim:\n",
    "    \n",
    "    def train(self, X_data, Y_data): #Takes X_data as an array of arrays containing only the values from the feature_data. \n",
    "        X_data = np.array(X_data)\n",
    "        Y_data = np.array(Y_data)\n",
    "        \n",
    "        self._num_instances, self._num_features = X_data.shape        \n",
    "        self._unique_classes = np.unique(Y_data)\n",
    "        self._num_unique_classes = len(self._unique_classes)\n",
    "        self._prior_probs = np.zeros(self._num_unique_classes) #Initialise the prior probabilities. \n",
    "\n",
    "        #Get Prior probabilities:\n",
    "        for i, c in enumerate(self._unique_classes):\n",
    "            instances_with_class_c = X_data[Y_data == c] #All the instances from X data that have the class c. \n",
    "            self._prior_probs[i] = instances_with_class_c.shape[0] / self._num_instances\n",
    "\n",
    "        #Get Posterior probabilties: \n",
    "        self._conditional_probs = {}\n",
    "        for x in range(self._num_features):\n",
    "            self._conditional_probs[x] = {c:self.get_posterior(x, c, X_data, Y_data) for c in self._unique_classes}\n",
    "\n",
    "\n",
    "    def get_posterior(self, w, c, X_data, Y_data):\n",
    "        #Returns the posterior probability, P(w|c):\n",
    "        posterior = 0\n",
    "        numerators = 0\n",
    "        denominators = 0\n",
    "        \n",
    "        instances_with_class_c = X_data[Y_data == c]#All the instances from X data that have the class c. \n",
    "        \n",
    "        for instance in instances_with_class_c:\n",
    "            numerators = numerators + instance[w]\n",
    "            denominators = denominators + sum(instance)\n",
    "        return (numerators + 1) / (denominators + self._num_features) #Adding 1 to numerator and |V| to denominator to avoid multiplying by zeroes. \n",
    "            \n",
    "    def make_predictions_on_X_data(self, new_X_data):\n",
    "        #Returns list of predictions for each instance in X data. \n",
    "        predictions = [self.make_prediction_on_instance(instance, new_X_data) for instance in new_X_data]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def make_prediction_on_instance(self, instance, new_X_data):       \n",
    "        #Returns the prediction of a single instance in X data. \n",
    "        \n",
    "        max_prob = 0 #Initialising greatest probability. \n",
    "        max_class = \"A\" #Initialising most likely class. \n",
    "\n",
    "        for i in range(len(self._unique_classes)): #For each class: \n",
    "            prob = 0 #Initialise the probability. \n",
    "            for w in self._conditional_probs.keys():\n",
    "                if instance[w] != 0: #Make sure instance[word] has a frequency. \n",
    "                    \n",
    "                    prob = prob + math.log((self._conditional_probs[w][self._unique_classes[i]] ** instance[w]), 2) #Grab the probability. \n",
    "                    \n",
    "                    #summing logs^                \n",
    "                    \n",
    "                    #####\n",
    "                    #probability is found by summing logarithims^ then multiplying by prior. \n",
    "                    #####\n",
    "                    \n",
    "            prob = prob + math.log(self._prior_probs[i], 2) #multiplying by prior.     \n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                max_class = self._unique_classes[i]\n",
    "                \n",
    "                \n",
    "        #Evaluate the class with the highest probability. \n",
    "        \n",
    "        return max_class\n",
    "       \n",
    "    def get_conditional_probs(self):\n",
    "        return self._conditional_probs\n",
    "    \n",
    "    def get_priors(self):\n",
    "        return  self._prior_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-fae0cdd28a82>:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(processed_array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data CV score: \n",
      "Average percentage of classes corrrectly classified on 10 splits =  3.28125\n",
      "\n",
      "Testing Data CV score: \n",
      "Average percentage of classes corrrectly classified on 10 splits =  3.0\n"
     ]
    }
   ],
   "source": [
    "#Training the model with with sum of logarithims and features having 200 words. \n",
    "\n",
    "\n",
    "#setting up X data and Y data:\n",
    "most_common_words = get_most_common_K_words(all_abstracts, 200)\n",
    "\n",
    "new_preprocessed_X_train = preprocess(X_train, most_common_words)\n",
    "new_preprocessed_X_test = preprocess(X_test, most_common_words)\n",
    "\n",
    "new_final_X_train, new_final_Y_train = values_only_no_IDS(new_preprocessed_X_train, Y_train)\n",
    "new_final_X_test, new_final_Y_test = values_only_no_IDS(new_preprocessed_X_test, Y_test)\n",
    "\n",
    "log_200_Naive_Bayes = NaiveBayesClassifierLogarithim()\n",
    "log_200_Naive_Bayes.train(np.array(new_final_X_train), np.array(new_final_Y_train))\n",
    "\n",
    "num_splits = 10\n",
    "CV_score = run_cross_validation(log_200_Naive_Bayes, X_train, Y_train, most_common_words, num_splits)\n",
    "print(\"Training Data CV score: \")\n",
    "print(\"Average percentage of classes corrrectly classified on\", num_splits, \"splits = \", CV_score) \n",
    "print()\n",
    "print(\"Testing Data CV score: \")\n",
    "test_CV_score = run_cross_validation(log_200_Naive_Bayes, X_test, Y_test, most_common_words, num_splits)\n",
    "print(\"Average percentage of classes corrrectly classified on\", num_splits, \"splits = \", test_CV_score) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a not an improvement, so I will not be using this for the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When trying to improve the model above, we found that the model best performed when it was fed with 200 words. using the original Naivebayes Class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-fae0cdd28a82>:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(processed_array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data CV Score:\n",
      "Average percentage of classes corrrectly classified on 10 splits =  82.875\n",
      "\n",
      "Testing Data CV Score:\n",
      "Average percentage of classes corrrectly classified on 10 splits =  76.25\n"
     ]
    }
   ],
   "source": [
    "final_nb = best_nb\n",
    "final_nb.train(np.array(new_final_X_train), np.array(new_final_Y_train))\n",
    "train_CV_score = run_cross_validation(final_nb, X_train, Y_train, most_common_words, num_splits)\n",
    "test_CV_score = run_cross_validation(final_nb, X_test, Y_test, most_common_words, num_splits)\n",
    "\n",
    "\n",
    "print(\"Training Data CV Score:\")\n",
    "print(\"Average percentage of classes corrrectly classified on\", num_splits, \"splits = \", train_CV_score) \n",
    "print()\n",
    "print(\"Testing Data CV Score:\")\n",
    "print(\"Average percentage of classes corrrectly classified on\", num_splits, \"splits = \", test_CV_score) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions on Test CSV File. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-3acf0d1cbeee>:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(feature_array)\n",
      "<ipython-input-8-fae0cdd28a82>:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(processed_array)\n"
     ]
    }
   ],
   "source": [
    "def values_only_no_IDS(X_data, Y_data):\n",
    "    #Return only the values of the arrays. (NaiveBayesClassifier does not use the IDS)\n",
    "    new_X = [x[1] for x in X_data]\n",
    "    new_Y = [y[1] for y in Y_data]    \n",
    "    return np.array(new_X), np.array(new_Y)\n",
    "\n",
    "def load_test_data(filename):\n",
    "    #load the data into a feature array, class array and list with all of the abstracts. \n",
    "    feature_array = []\n",
    "    data = np.loadtxt(filename, dtype = str, delimiter = \",\")\n",
    "    for row in data[1:]: \n",
    "        feature_array.append((int(row[0]), row[1].split()))\n",
    "    return np.array(feature_array)\n",
    "\n",
    "test_filename = \"data/tst.csv\" \n",
    "\n",
    "data = load_test_data(test_filename)\n",
    "\n",
    "processed_data = preprocess(data, most_common_words)\n",
    "\n",
    "proceased_data_as_only_values = [x[1] for x in processed_data]\n",
    "\n",
    "\n",
    "cleaned_processed_data = np.array(proceased_data_as_only_values)\n",
    "predictions = []\n",
    "\n",
    "for i in range(len(processed_data)):\n",
    "    instance = processed_data[i]\n",
    "    ID = instance[0]\n",
    "    value = instance[1]\n",
    "    prediction = final_nb.make_prediction_on_instance(value, cleaned_processed_data)\n",
    "    predictions.append((ID, prediction))\n",
    "\n",
    "#Write predictions to a csv file\n",
    "import csv\n",
    "with open(\"data/test_predictions.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow((\"id\", \"class\"))\n",
    "    for item in predictions:\n",
    "        writer.writerow(item)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'B'), (2, 'E'), (3, 'A'), (4, 'E'), (5, 'E'), (6, 'E'), (7, 'E'), (8, 'B'), (9, 'B'), (10, 'B'), (11, 'A'), (12, 'E'), (13, 'B'), (14, 'B'), (15, 'E'), (16, 'E'), (17, 'E'), (18, 'B'), (19, 'E'), (20, 'B'), (21, 'B'), (22, 'E'), (23, 'B'), (24, 'B'), (25, 'E'), (26, 'E'), (27, 'E'), (28, 'V'), (29, 'B'), (30, 'E'), (31, 'E'), (32, 'B'), (33, 'E'), (34, 'E'), (35, 'B'), (36, 'V'), (37, 'E'), (38, 'E'), (39, 'B'), (40, 'E'), (41, 'E'), (42, 'B'), (43, 'E'), (44, 'E'), (45, 'E'), (46, 'E'), (47, 'E'), (48, 'B'), (49, 'B'), (50, 'E'), (51, 'E'), (52, 'E'), (53, 'E'), (54, 'B'), (55, 'B'), (56, 'B'), (57, 'E'), (58, 'A'), (59, 'B'), (60, 'B'), (61, 'E'), (62, 'E'), (63, 'E'), (64, 'B'), (65, 'E'), (66, 'B'), (67, 'E'), (68, 'B'), (69, 'E'), (70, 'E'), (71, 'E'), (72, 'E'), (73, 'E'), (74, 'E'), (75, 'E'), (76, 'V'), (77, 'E'), (78, 'B'), (79, 'E'), (80, 'B'), (81, 'E'), (82, 'B'), (83, 'E'), (84, 'E'), (85, 'B'), (86, 'E'), (87, 'E'), (88, 'V'), (89, 'B'), (90, 'E'), (91, 'E'), (92, 'E'), (93, 'B'), (94, 'B'), (95, 'E'), (96, 'E'), (97, 'V'), (98, 'E'), (99, 'E'), (100, 'B'), (101, 'B'), (102, 'V'), (103, 'E'), (104, 'E'), (105, 'E'), (106, 'B'), (107, 'V'), (108, 'E'), (109, 'B'), (110, 'B'), (111, 'B'), (112, 'E'), (113, 'E'), (114, 'B'), (115, 'B'), (116, 'E'), (117, 'B'), (118, 'B'), (119, 'V'), (120, 'E'), (121, 'B'), (122, 'E'), (123, 'E'), (124, 'E'), (125, 'V'), (126, 'E'), (127, 'B'), (128, 'V'), (129, 'E'), (130, 'B'), (131, 'E'), (132, 'E'), (133, 'V'), (134, 'E'), (135, 'B'), (136, 'B'), (137, 'B'), (138, 'E'), (139, 'B'), (140, 'B'), (141, 'E'), (142, 'B'), (143, 'E'), (144, 'E'), (145, 'E'), (146, 'E'), (147, 'E'), (148, 'E'), (149, 'B'), (150, 'B'), (151, 'B'), (152, 'V'), (153, 'E'), (154, 'A'), (155, 'E'), (156, 'B'), (157, 'B'), (158, 'A'), (159, 'E'), (160, 'E'), (161, 'E'), (162, 'E'), (163, 'B'), (164, 'B'), (165, 'B'), (166, 'E'), (167, 'B'), (168, 'E'), (169, 'A'), (170, 'E'), (171, 'E'), (172, 'E'), (173, 'B'), (174, 'E'), (175, 'B'), (176, 'E'), (177, 'B'), (178, 'E'), (179, 'E'), (180, 'V'), (181, 'E'), (182, 'E'), (183, 'E'), (184, 'E'), (185, 'B'), (186, 'A'), (187, 'E'), (188, 'E'), (189, 'B'), (190, 'A'), (191, 'A'), (192, 'B'), (193, 'B'), (194, 'E'), (195, 'B'), (196, 'A'), (197, 'B'), (198, 'V'), (199, 'V'), (200, 'E'), (201, 'E'), (202, 'E'), (203, 'B'), (204, 'V'), (205, 'E'), (206, 'B'), (207, 'E'), (208, 'B'), (209, 'E'), (210, 'B'), (211, 'B'), (212, 'B'), (213, 'E'), (214, 'E'), (215, 'E'), (216, 'E'), (217, 'B'), (218, 'E'), (219, 'E'), (220, 'E'), (221, 'E'), (222, 'B'), (223, 'E'), (224, 'B'), (225, 'B'), (226, 'E'), (227, 'B'), (228, 'B'), (229, 'B'), (230, 'B'), (231, 'B'), (232, 'E'), (233, 'E'), (234, 'E'), (235, 'B'), (236, 'E'), (237, 'E'), (238, 'E'), (239, 'E'), (240, 'E'), (241, 'E'), (242, 'A'), (243, 'B'), (244, 'B'), (245, 'E'), (246, 'B'), (247, 'E'), (248, 'V'), (249, 'B'), (250, 'A'), (251, 'E'), (252, 'E'), (253, 'B'), (254, 'E'), (255, 'E'), (256, 'B'), (257, 'B'), (258, 'E'), (259, 'E'), (260, 'E'), (261, 'B'), (262, 'B'), (263, 'E'), (264, 'E'), (265, 'E'), (266, 'E'), (267, 'B'), (268, 'B'), (269, 'A'), (270, 'E'), (271, 'E'), (272, 'B'), (273, 'B'), (274, 'E'), (275, 'B'), (276, 'E'), (277, 'V'), (278, 'V'), (279, 'E'), (280, 'B'), (281, 'E'), (282, 'E'), (283, 'V'), (284, 'E'), (285, 'B'), (286, 'E'), (287, 'V'), (288, 'E'), (289, 'E'), (290, 'V'), (291, 'B'), (292, 'B'), (293, 'B'), (294, 'A'), (295, 'E'), (296, 'B'), (297, 'B'), (298, 'E'), (299, 'E'), (300, 'B'), (301, 'A'), (302, 'B'), (303, 'E'), (304, 'E'), (305, 'B'), (306, 'A'), (307, 'B'), (308, 'E'), (309, 'E'), (310, 'E'), (311, 'E'), (312, 'E'), (313, 'A'), (314, 'V'), (315, 'V'), (316, 'E'), (317, 'E'), (318, 'E'), (319, 'E'), (320, 'A'), (321, 'B'), (322, 'B'), (323, 'E'), (324, 'B'), (325, 'E'), (326, 'B'), (327, 'B'), (328, 'E'), (329, 'B'), (330, 'B'), (331, 'E'), (332, 'B'), (333, 'E'), (334, 'B'), (335, 'A'), (336, 'E'), (337, 'V'), (338, 'E'), (339, 'E'), (340, 'E'), (341, 'E'), (342, 'B'), (343, 'E'), (344, 'E'), (345, 'E'), (346, 'A'), (347, 'B'), (348, 'B'), (349, 'V'), (350, 'B'), (351, 'B'), (352, 'B'), (353, 'B'), (354, 'B'), (355, 'B'), (356, 'E'), (357, 'V'), (358, 'B'), (359, 'E'), (360, 'E'), (361, 'B'), (362, 'E'), (363, 'E'), (364, 'B'), (365, 'B'), (366, 'B'), (367, 'E'), (368, 'B'), (369, 'E'), (370, 'B'), (371, 'B'), (372, 'E'), (373, 'B'), (374, 'B'), (375, 'E'), (376, 'B'), (377, 'B'), (378, 'A'), (379, 'V'), (380, 'B'), (381, 'B'), (382, 'A'), (383, 'E'), (384, 'E'), (385, 'E'), (386, 'E'), (387, 'A'), (388, 'A'), (389, 'V'), (390, 'E'), (391, 'B'), (392, 'V'), (393, 'V'), (394, 'E'), (395, 'B'), (396, 'E'), (397, 'B'), (398, 'E'), (399, 'E'), (400, 'E'), (401, 'E'), (402, 'B'), (403, 'E'), (404, 'B'), (405, 'B'), (406, 'E'), (407, 'V'), (408, 'E'), (409, 'B'), (410, 'E'), (411, 'E'), (412, 'B'), (413, 'E'), (414, 'B'), (415, 'B'), (416, 'E'), (417, 'E'), (418, 'B'), (419, 'E'), (420, 'B'), (421, 'E'), (422, 'B'), (423, 'E'), (424, 'B'), (425, 'E'), (426, 'B'), (427, 'E'), (428, 'B'), (429, 'E'), (430, 'B'), (431, 'E'), (432, 'E'), (433, 'E'), (434, 'E'), (435, 'A'), (436, 'E'), (437, 'B'), (438, 'E'), (439, 'B'), (440, 'E'), (441, 'E'), (442, 'E'), (443, 'E'), (444, 'E'), (445, 'E'), (446, 'B'), (447, 'B'), (448, 'A'), (449, 'E'), (450, 'B'), (451, 'B'), (452, 'E'), (453, 'B'), (454, 'E'), (455, 'E'), (456, 'B'), (457, 'E'), (458, 'E'), (459, 'E'), (460, 'E'), (461, 'E'), (462, 'B'), (463, 'B'), (464, 'B'), (465, 'E'), (466, 'E'), (467, 'A'), (468, 'B'), (469, 'B'), (470, 'B'), (471, 'E'), (472, 'E'), (473, 'B'), (474, 'E'), (475, 'V'), (476, 'E'), (477, 'B'), (478, 'E'), (479, 'E'), (480, 'A'), (481, 'E'), (482, 'B'), (483, 'B'), (484, 'B'), (485, 'B'), (486, 'E'), (487, 'B'), (488, 'E'), (489, 'E'), (490, 'B'), (491, 'E'), (492, 'E'), (493, 'E'), (494, 'B'), (495, 'E'), (496, 'E'), (497, 'V'), (498, 'B'), (499, 'V'), (500, 'E'), (501, 'E'), (502, 'E'), (503, 'B'), (504, 'B'), (505, 'E'), (506, 'V'), (507, 'E'), (508, 'V'), (509, 'E'), (510, 'B'), (511, 'V'), (512, 'E'), (513, 'A'), (514, 'E'), (515, 'B'), (516, 'E'), (517, 'B'), (518, 'B'), (519, 'B'), (520, 'B'), (521, 'B'), (522, 'B'), (523, 'E'), (524, 'E'), (525, 'E'), (526, 'B'), (527, 'A'), (528, 'B'), (529, 'B'), (530, 'E'), (531, 'B'), (532, 'B'), (533, 'E'), (534, 'E'), (535, 'B'), (536, 'E'), (537, 'E'), (538, 'A'), (539, 'A'), (540, 'B'), (541, 'E'), (542, 'B'), (543, 'B'), (544, 'E'), (545, 'A'), (546, 'V'), (547, 'V'), (548, 'E'), (549, 'V'), (550, 'B'), (551, 'B'), (552, 'B'), (553, 'E'), (554, 'B'), (555, 'E'), (556, 'B'), (557, 'E'), (558, 'B'), (559, 'B'), (560, 'B'), (561, 'E'), (562, 'E'), (563, 'B'), (564, 'E'), (565, 'E'), (566, 'V'), (567, 'E'), (568, 'E'), (569, 'E'), (570, 'V'), (571, 'E'), (572, 'E'), (573, 'B'), (574, 'B'), (575, 'E'), (576, 'B'), (577, 'B'), (578, 'E'), (579, 'E'), (580, 'E'), (581, 'E'), (582, 'B'), (583, 'E'), (584, 'E'), (585, 'E'), (586, 'E'), (587, 'E'), (588, 'B'), (589, 'E'), (590, 'B'), (591, 'B'), (592, 'E'), (593, 'V'), (594, 'E'), (595, 'B'), (596, 'E'), (597, 'B'), (598, 'B'), (599, 'B'), (600, 'B'), (601, 'E'), (602, 'E'), (603, 'B'), (604, 'A'), (605, 'E'), (606, 'E'), (607, 'B'), (608, 'B'), (609, 'V'), (610, 'B'), (611, 'V'), (612, 'B'), (613, 'E'), (614, 'B'), (615, 'B'), (616, 'B'), (617, 'B'), (618, 'B'), (619, 'E'), (620, 'V'), (621, 'A'), (622, 'E'), (623, 'E'), (624, 'A'), (625, 'A'), (626, 'V'), (627, 'V'), (628, 'A'), (629, 'B'), (630, 'B'), (631, 'V'), (632, 'E'), (633, 'A'), (634, 'E'), (635, 'B'), (636, 'E'), (637, 'E'), (638, 'E'), (639, 'E'), (640, 'E'), (641, 'B'), (642, 'B'), (643, 'E'), (644, 'B'), (645, 'E'), (646, 'B'), (647, 'B'), (648, 'B'), (649, 'V'), (650, 'V'), (651, 'B'), (652, 'A'), (653, 'E'), (654, 'E'), (655, 'E'), (656, 'E'), (657, 'E'), (658, 'B'), (659, 'B'), (660, 'B'), (661, 'V'), (662, 'E'), (663, 'B'), (664, 'E'), (665, 'B'), (666, 'B'), (667, 'E'), (668, 'E'), (669, 'E'), (670, 'E'), (671, 'E'), (672, 'E'), (673, 'E'), (674, 'B'), (675, 'E'), (676, 'E'), (677, 'E'), (678, 'B'), (679, 'E'), (680, 'E'), (681, 'V'), (682, 'E'), (683, 'B'), (684, 'B'), (685, 'E'), (686, 'E'), (687, 'B'), (688, 'E'), (689, 'B'), (690, 'E'), (691, 'B'), (692, 'V'), (693, 'B'), (694, 'E'), (695, 'E'), (696, 'B'), (697, 'E'), (698, 'A'), (699, 'B'), (700, 'A'), (701, 'E'), (702, 'E'), (703, 'E'), (704, 'E'), (705, 'E'), (706, 'V'), (707, 'B'), (708, 'B'), (709, 'E'), (710, 'A'), (711, 'E'), (712, 'B'), (713, 'E'), (714, 'B'), (715, 'V'), (716, 'B'), (717, 'B'), (718, 'B'), (719, 'E'), (720, 'E'), (721, 'E'), (722, 'B'), (723, 'E'), (724, 'E'), (725, 'B'), (726, 'E'), (727, 'E'), (728, 'V'), (729, 'E'), (730, 'E'), (731, 'E'), (732, 'B'), (733, 'B'), (734, 'E'), (735, 'E'), (736, 'B'), (737, 'E'), (738, 'E'), (739, 'E'), (740, 'E'), (741, 'B'), (742, 'E'), (743, 'A'), (744, 'E'), (745, 'V'), (746, 'V'), (747, 'B'), (748, 'B'), (749, 'E'), (750, 'A'), (751, 'B'), (752, 'B'), (753, 'E'), (754, 'E'), (755, 'B'), (756, 'B'), (757, 'E'), (758, 'E'), (759, 'A'), (760, 'E'), (761, 'B'), (762, 'E'), (763, 'E'), (764, 'B'), (765, 'B'), (766, 'B'), (767, 'B'), (768, 'E'), (769, 'E'), (770, 'E'), (771, 'E'), (772, 'E'), (773, 'E'), (774, 'E'), (775, 'B'), (776, 'B'), (777, 'E'), (778, 'E'), (779, 'B'), (780, 'V'), (781, 'E'), (782, 'B'), (783, 'B'), (784, 'A'), (785, 'B'), (786, 'B'), (787, 'E'), (788, 'B'), (789, 'E'), (790, 'B'), (791, 'E'), (792, 'E'), (793, 'B'), (794, 'E'), (795, 'E'), (796, 'E'), (797, 'A'), (798, 'V'), (799, 'B'), (800, 'B'), (801, 'E'), (802, 'B'), (803, 'A'), (804, 'B'), (805, 'E'), (806, 'E'), (807, 'B'), (808, 'E'), (809, 'E'), (810, 'E'), (811, 'E'), (812, 'E'), (813, 'B'), (814, 'E'), (815, 'B'), (816, 'V'), (817, 'B'), (818, 'B'), (819, 'E'), (820, 'A'), (821, 'B'), (822, 'E'), (823, 'E'), (824, 'B'), (825, 'E'), (826, 'E'), (827, 'E'), (828, 'B'), (829, 'E'), (830, 'B'), (831, 'V'), (832, 'E'), (833, 'E'), (834, 'E'), (835, 'E'), (836, 'V'), (837, 'E'), (838, 'B'), (839, 'B'), (840, 'B'), (841, 'E'), (842, 'B'), (843, 'E'), (844, 'E'), (845, 'B'), (846, 'A'), (847, 'B'), (848, 'B'), (849, 'E'), (850, 'E'), (851, 'E'), (852, 'B'), (853, 'E'), (854, 'B'), (855, 'B'), (856, 'E'), (857, 'E'), (858, 'E'), (859, 'B'), (860, 'B'), (861, 'E'), (862, 'B'), (863, 'E'), (864, 'E'), (865, 'E'), (866, 'E'), (867, 'B'), (868, 'B'), (869, 'E'), (870, 'B'), (871, 'B'), (872, 'B'), (873, 'B'), (874, 'E'), (875, 'V'), (876, 'E'), (877, 'A'), (878, 'E'), (879, 'E'), (880, 'E'), (881, 'E'), (882, 'B'), (883, 'B'), (884, 'B'), (885, 'B'), (886, 'B'), (887, 'B'), (888, 'B'), (889, 'B'), (890, 'E'), (891, 'E'), (892, 'E'), (893, 'B'), (894, 'E'), (895, 'E'), (896, 'B'), (897, 'E'), (898, 'E'), (899, 'E'), (900, 'E'), (901, 'E'), (902, 'B'), (903, 'V'), (904, 'E'), (905, 'E'), (906, 'E'), (907, 'E'), (908, 'E'), (909, 'E'), (910, 'A'), (911, 'E'), (912, 'E'), (913, 'E'), (914, 'B'), (915, 'B'), (916, 'E'), (917, 'A'), (918, 'V'), (919, 'E'), (920, 'E'), (921, 'E'), (922, 'B'), (923, 'E'), (924, 'E'), (925, 'E'), (926, 'E'), (927, 'E'), (928, 'E'), (929, 'B'), (930, 'B'), (931, 'E'), (932, 'E'), (933, 'E'), (934, 'B'), (935, 'E'), (936, 'E'), (937, 'E'), (938, 'V'), (939, 'E'), (940, 'E'), (941, 'E'), (942, 'B'), (943, 'E'), (944, 'A'), (945, 'E'), (946, 'E'), (947, 'E'), (948, 'E'), (949, 'E'), (950, 'E'), (951, 'V'), (952, 'B'), (953, 'E'), (954, 'E'), (955, 'E'), (956, 'B'), (957, 'B'), (958, 'A'), (959, 'E'), (960, 'E'), (961, 'E'), (962, 'B'), (963, 'B'), (964, 'B'), (965, 'B'), (966, 'E'), (967, 'E'), (968, 'E'), (969, 'B'), (970, 'E'), (971, 'E'), (972, 'B'), (973, 'B'), (974, 'E'), (975, 'V'), (976, 'E'), (977, 'B'), (978, 'B'), (979, 'E'), (980, 'E'), (981, 'E'), (982, 'E'), (983, 'B'), (984, 'E'), (985, 'E'), (986, 'B'), (987, 'B'), (988, 'B'), (989, 'E'), (990, 'A'), (991, 'E'), (992, 'E'), (993, 'B'), (994, 'E'), (995, 'B'), (996, 'B'), (997, 'E'), (998, 'B'), (999, 'A'), (1000, 'E')]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
